{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Approximating natural languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(fname):\n",
    "    with open(fname) as f:\n",
    "        return f.read()\n",
    "    \n",
    "    \n",
    "hamlet = load_file(\"corpus/norm_hamlet.txt\")\n",
    "romeo = load_file(\"corpus/norm_romeo_and_juliet.txt\")\n",
    "wiki = load_file(\"corpus/norm_wiki_sample.txt\")\n",
    "\n",
    "corpus = [hamlet, romeo, wiki]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Zeroth-order approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja 27 zankowego alfabetu.\n",
    "# 'a' do 'z' + ' '\n",
    "alphabet = [chr(ord('a') + i) for i in range(26)]\n",
    "alphabet.append(\" \")\n",
    "\n",
    "# Długość generowanego textu\n",
    "text_len = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_len(text):\n",
    "    words = text.split(\" \")\n",
    "    return sum([len(w) for w in words]) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia długość wyrazu 25.98038527951651\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "zeroth_order_text = \"\".join(random.choices(alphabet, k=text_len))\n",
    "zeroth_avg_word_len = avg_word_len(zeroth_order_text)\n",
    "\n",
    "print(\"Średnia długość wyrazu\", zeroth_avg_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Frequency of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 37 artists>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def probability(text):\n",
    "    counter = Counter(text)\n",
    "    return dict([(token, count / len(text)) for token, count in counter.items()])\n",
    "\n",
    "merged_text = \"\".join(corpus)\n",
    "letters_prob = probability(merged_text)\n",
    "most_common_letters = sorted(letters_prob.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.bar(*zip(*most_common_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  First-order approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia długość wyrazu: 4.856864238022725\n"
     ]
    }
   ],
   "source": [
    "first_order_text = \"\".join(random.choices(list(letters_prob.keys()), weights=list(letters_prob.values()), k=text_len))\n",
    "first_avg_word_len = avg_word_len(first_order_text)\n",
    "\n",
    "print(\"Średnia długość wyrazu:\", first_avg_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  Conditional probability of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(text, seq_len):\n",
    "    return [text[i:i+seq_len] for i in range(len(text) - seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dwa najczęsciej pojawiające się znaki: [' ', 'e']\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "two_most_common_letters = [l for l, p in most_common_letters[:2]]\n",
    "\n",
    "print(\"Dwa najczęsciej pojawiające się znaki:\", two_most_common_letters)\n",
    "\n",
    "\n",
    "seqs = get_seq(merged_text, 2)\n",
    "seqs_prob = probability(seqs)\n",
    "\n",
    "print(dict())\n",
    "\n",
    "\n",
    "\n",
    "# def sequences_prob(text, letters_p, seq_len):\n",
    "#     seqs = [text[i:i + seq_len for i in range(len(text) - lookback)]\n",
    "#     seqs_prob = probability(seqs)\n",
    "#     return seqs_prob\n",
    "\n",
    "\n",
    "# seq_2_prob = sequences_prob(merged_text, letters_prob, 1)\n",
    "\n",
    "    \n",
    "\n",
    "# # P(i,j)\n",
    "# letter_pairs_prob = probability(letter_pairs)\n",
    "\n",
    "# # P(j|i) = P(i,j) / P(i)\n",
    "# condtional_prob = {f\"{l[1]}|{l[0]}\": p / letters_prob[l[0]] for l, p in letter_pairs_prob.items()}\n",
    "# condtional_prob\n",
    "\n",
    "# # for letter, prob in most_common_letters[:2]:\n",
    "# #     print([(l,p) for l, p in condtional_prob.items() if l == letter])\n",
    "\n",
    "# # print(list(zip(letter_pairs, letter_pairs_freq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  Approximations based on Markov sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
